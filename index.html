<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Nerfies: Deformable Neural Radiance Fields</title>
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">
  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">A Simple Baseline for Latent-Cascaded Video Super-Resolution</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">Anonymous Authors</span>
          </div>
          <!-- Paper video. -->
          <div class="columns is-centered has-text-centered">
            <div class="column is-four-fifths">
              <div class="publication-video">
                <iframe src="https://www.youtube.com/embed/MrKrnHhk8IA?rel=0&amp;showinfo=0"
                        frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
              </div>
            </div>
          </div>
          <!--/ Paper video. -->
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Latent diffusion models have emerged as a leading paradigm for efficient video generation. However, as user expectations shift toward higher-resolution outputs, relying solely on latent computation becomes inadequate. A promising approach involves decoupling the process into two stages: semantic content generation and detail synthesis. The former employs a computationally intensive base model at lower resolutions, while the latter leverages a lightweight cascaded video super-resolution (VSR) model to achieve high-resolution output. In this work, we focus on studying key design principles for latter cascaded VSR models, which are underexplored currently. First, we propose two degradation strategies to generate training pairs that better mimic the output characteristics of the base model, ensuring alignment between the VSR model and its upstream generator. Second, we provide critical insights into VSR model behavior through systematic analysis of (1) timestep sampling strategies, (2) noise augmentation effects on low-resolution (LR) inputs. These findings directly inform our architectural and training innovations. Finally, we introduce interleaving temporal unit and sparse local attention to achieve efficient training and inference, drastically reducing computational overhead. Extensive experiments demonstrate the superiority of our framework over existing methods, with ablation studies confirming the efficacy of each design choice. Our work establishes a simple yet effective baseline for cascaded video super-resolution generation, offering practical insights to guide future advancements in efficient cascaded synthesis systems.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Method</h2>
        <div class="content has-text-justified">
  <p>
    Our cascaded video generation framework operates within a latent space defined by a pre-trained VAE. The framework comprises two core components:
    (i) A computationally intensive base Text-to-Video (T2V) model, which employs a Diffusion Transformer (DiT) architecture to generate low-resolution video latent representations.
    (ii) A cascaded latent video super-resolution model, termed SimpleGVR, which adopts a lightweight architecture to efficiently enhance the base model’s output into high-resolution video latent representations.
  </p>
  <br>
  <img src="./static/images/pipeline.jpg" alt="Method Page 1" style="width: 100%; margin-bottom: 1rem;">
</div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Result</h2>
        <div class="content has-text-justified">
          <!-- You can fill in the results details here -->
        </div>
      </div>
    </div>
  </div>
  <!-- 滚动播放 -->
  <div class="container is-max-desktop">
    <h2 class="title is-3 has-text-centered">Interactive Video Carousel</h2>
    <div class="carousel-container" style="position: relative; overflow: hidden;">
      <button class="carousel-button left" onclick="scrollCarousel(-1)">&#10094;</button>
      <div class="carousel-track" style="display: flex; transition: transform 0.5s ease;">
        <!-- Video Group 1 -->
        <div class="carousel-item" style="flex: 0 0 100%; padding: 1rem;">
          <div class="video-slider-wrapper" style="position: relative; width: 100%; height: 0; padding-bottom: 56.25%;">
            <video src="./static/videos/1_hr.mp4" autoplay loop muted style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; object-fit: cover; clip-path: inset(0 50% 0 0);"></video>
            <video src="./static/videos/1_hr.mp4" autoplay loop muted style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; object-fit: cover;"></video>
            <input type="range" min="0" max="100" value="50" class="slider" style="position: absolute; bottom: 10px; left: 0; width: 100%; opacity: 0.7;">
          </div>
        </div>
        <!-- Repeat similar blocks for Group 2, 3, 4 -->
      </div>
      <button class="carousel-button right" onclick="scrollCarousel(1)">&#10095;</button>
    </div>
  </div>
  <script>
    const track = document.querySelector('.carousel-track');
    let currentIndex = 0;

    function scrollCarousel(direction) {
      const items = document.querySelectorAll('.carousel-item');
      const totalItems = items.length;
      currentIndex = (currentIndex + direction + totalItems) % totalItems;
      track.style.transform = `translateX(-${currentIndex * 100}%)`;
    }

    document.querySelectorAll('.slider').forEach((slider, index) => {
      slider.addEventListener('input', (e) => {
        const val = e.target.value;
        const leftVideo = e.target.parentElement.querySelectorAll('video')[0];
        leftVideo.style.clipPath = `inset(0 ${100 - val}% 0 0)`;
      });
    });
  </script>
  <!-- 滚动播放 -->
</section>

</body>
</html>
